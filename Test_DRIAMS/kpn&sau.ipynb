{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from tensorflow.keras.layers import MaxPool2D, GlobalMaxPool2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Conv2D, Concatenate,Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import cv2\n",
    "from joblib import load, dump\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import recall_score,precision_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, average_precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,RepeatedKFold,RepeatedStratifiedKFold, train_test_split\n",
    "from aggmap import AggMap, AggMapNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = '/raid/lzyt_dir/Data_DRIAMS/Redo'\n",
    "Xpath = '/mnt/lzyt/DRIAMS/A'\n",
    "gpuid = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpuid\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']=\"TRUE\"\n",
    "physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_gpus[0], True)    #动态调用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception(inputs, units = 8, strides = 1):\n",
    "    \"\"\"\n",
    "    naive google inception block\n",
    "    \"\"\"\n",
    "    x1 = Conv2D(units, 5, padding='same', activation = 'relu', strides = strides)(inputs)\n",
    "    x2 = Conv2D(units, 3, padding='same', activation = 'relu', strides = strides)(inputs)\n",
    "    x3 = Conv2D(units, 1, padding='same', activation = 'relu', strides = strides)(inputs)\n",
    "    outputs = Concatenate()([x1, x2, x3])\n",
    "    outputs = BatchNormalization(axis=-1, epsilon=1e-5, momentum=0.8)(outputs)    \n",
    "    return outputs\n",
    "def MK(inputs, units = [12, 24, 48], strides = 1):\n",
    "    \"\"\"\n",
    "    multikernel block\n",
    "    \"\"\"\n",
    "    x1 = Conv2D(units[0], 7, padding='same', activation = 'relu', strides = strides)(inputs)\n",
    "    x2 = Conv2D(units[1], 5, padding='same', activation = 'relu', strides = strides)(inputs)\n",
    "    x3 = Conv2D(units[2], 3, padding='same', activation = 'relu', strides = strides)(inputs)\n",
    "    outputs = Concatenate()([x1, x2, x3])\n",
    "    outputs = BatchNormalization(axis=-1, epsilon=1e-5, momentum=0.8)(outputs)    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _MALDINet(input_shape,  \n",
    "               n_outputs = 1, \n",
    "               n_inception = 2,\n",
    "               dense_layers = [256, 128, 64, 32], \n",
    "               dense_avf = 'relu', \n",
    "               dropout = 0,\n",
    "               last_avf = 'softmax'):\n",
    "\n",
    "    \"\"\"\n",
    "    parameters\n",
    "    ----------------------\n",
    "    input_shape: w, h, c\n",
    "    n_outputs: output units\n",
    "    n_inception: number of the inception layers\n",
    "    dense_layers: list, how many dense layers and units\n",
    "    dense_avf: activation function for dense layers\n",
    "    last_avf: activation function for last layer\n",
    "    dropout: dropout of the dense layers\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    assert len(input_shape) == 3\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    incept = MK(inputs=inputs)\n",
    "\n",
    "    for i in range(n_inception):\n",
    "        incept = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(incept) #p1\n",
    "        incept = Inception(incept, strides = 1, units = 32*(2**i))\n",
    "\n",
    "    #flatten\n",
    "    x = GlobalMaxPool2D()(incept)\n",
    "    \n",
    "    ## dense layer\n",
    "    for units in dense_layers:\n",
    "        x = Dense(units, activation = dense_avf)(x)\n",
    "        if dropout:\n",
    "            x = Dropout(rate = dropout)(x)\n",
    "\n",
    "    #last layer\n",
    "    outputs = Dense(n_outputs,activation = last_avf)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "specie = 'Kpn'\n",
    "DRUGS = ['cip', 'ceft', 'cefe', 'mero', 'tob']\n",
    "DROPOUT = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "EPOCHS = [40, 60, 80, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug in DRUGS :\n",
    "    #加载标签及图像数据\n",
    "    Labels = pd.read_csv(os.path.join(source_path, str(specie), str(drug), 'clean_labels.csv'),header=None)\n",
    "    train_Y = np.zeros((len(Labels),2))\n",
    "    i = 0\n",
    "    for label in Labels[0]:\n",
    "        if label == 0:\n",
    "            train_Y[i,0] = 1\n",
    "        else:\n",
    "            train_Y[i,1] = 1\n",
    "        i += 1\n",
    "    y = train_Y.astype(int)\n",
    "    X = load(os.path.join(Xpath, str(specie),'Xdata', f\"X_{specie}_{drug}.data\"))\n",
    "    #分割数据集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for dropout, epochs in itertools.product(DROPOUT, EPOCHS):\n",
    "        #编译及训练模型\n",
    "        model = _MALDINet(X.shape[1:], n_outputs=y.shape[-1], dropout=dropout)\n",
    "        opt = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "        auc_metric = tf.keras.metrics.AUC(curve='ROC')\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[auc_metric])\n",
    "        history = model.fit(X_train, y_train, batch_size=64, epochs=epochs, verbose=0)\n",
    "        # 计算测试集AUC并记录\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_auc = roc_auc_score(y_test, y_pred)\n",
    "        with open(\"output_kpn.txt\", \"a\") as file:\n",
    "            file.write(drug + ' dropout = ' + str(dropout) + ' epochs = ' + str(epochs) + ' auc = ' + str(test_auc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "specie = 'Sau'\n",
    "DRUGS = ['cip', 'fus', 'oxa']\n",
    "DROPOUT = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "EPOCHS = [40, 60, 80, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug in DRUGS :\n",
    "    #加载标签及图像数据\n",
    "    Labels = pd.read_csv(os.path.join(source_path, str(specie), str(drug), 'clean_labels.csv'),header=None)\n",
    "    train_Y = np.zeros((len(Labels),2))\n",
    "    i = 0\n",
    "    for label in Labels[0]:\n",
    "        if label == 0:\n",
    "            train_Y[i,0] = 1\n",
    "        else:\n",
    "            train_Y[i,1] = 1\n",
    "        i += 1\n",
    "    y = train_Y.astype(int)\n",
    "    X = load(os.path.join(Xpath, str(specie),'Xdata', f\"X_{specie}_{drug}.data\"))\n",
    "    #分割数据集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for dropout, epochs in itertools.product(DROPOUT, EPOCHS):\n",
    "        #编译及训练模型\n",
    "        model = _MALDINet(X.shape[1:], n_outputs=y.shape[-1], dropout=dropout)\n",
    "        opt = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "        auc_metric = tf.keras.metrics.AUC(curve='ROC')\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[auc_metric])\n",
    "        history = model.fit(X_train, y_train, batch_size=64, epochs=epochs, verbose=0)\n",
    "        # 计算测试集AUC并记录\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_auc = roc_auc_score(y_test, y_pred)\n",
    "        with open(\"output_sau.txt\", \"a\") as file:\n",
    "            file.write(drug + ' dropout = ' + str(dropout) + ' epochs = ' + str(epochs) + ' auc = ' + str(test_auc) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
